#!/usr/bin/env python3
"""
æµ‹è¯•train_sweep.pyçš„æ‰€æœ‰ä¾èµ–å’ŒåŠŸèƒ½
"""

import sys
from pathlib import Path

print("="*60)
print("ğŸ” æ£€æŸ¥ train_sweep.py ä¾èµ–")
print("="*60)

# 1. æµ‹è¯•å¯¼å…¥
print("\n1ï¸âƒ£ æµ‹è¯•å¯¼å…¥...")
try:
    from src.config import Config
    print("   âœ… Config")
except Exception as e:
    print(f"   âŒ Config: {e}")
    sys.exit(1)

try:
    from src.data_io import load_data
    print("   âœ… load_data")
except Exception as e:
    print(f"   âŒ load_data: {e}")
    sys.exit(1)

try:
    from src.features import prepare_sequences
    print("   âœ… prepare_sequences")
except Exception as e:
    print(f"   âŒ prepare_sequences: {e}")
    sys.exit(1)

try:
    from src.models.transformer import TransformerForecaster
    print("   âœ… TransformerModel")
except Exception as e:
    print(f"   âŒ TransformerModel: {e}")
    sys.exit(1)

try:
    from src.cv import rolling_origin_split
    print("   âœ… rolling_origin_split")
except Exception as e:
    print(f"   âŒ rolling_origin_split: {e}")
    sys.exit(1)

try:
    from src.metrics import eval_metrics
    print("   âœ… eval_metrics")
except Exception as e:
    print(f"   âŒ eval_metrics: {e}")
    sys.exit(1)

# 2. æµ‹è¯•é…ç½®åŠ è½½
print("\n2ï¸âƒ£ æµ‹è¯•é…ç½®åŠ è½½...")
try:
    config = Config("config_sweep.yaml")
    print("   âœ… config_sweep.yaml åŠ è½½æˆåŠŸ")
    
    # æµ‹è¯•è®¿é—®å„ç§é…ç½®
    models = config.config.get('models', {})
    features = config.config.get('features', {})
    data_cfg = config.config.get('data', {})
    target_cfg = config.config.get('target', {})
    
    print(f"   âœ… modelsé…ç½®å­˜åœ¨: {bool(models)}")
    print(f"   âœ… featuresé…ç½®å­˜åœ¨: {bool(features)}")
    print(f"   âœ… dataé…ç½®å­˜åœ¨: {bool(data_cfg)}")
    print(f"   âœ… targeté…ç½®å­˜åœ¨: {bool(target_cfg)}")
    
except Exception as e:
    print(f"   âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 3. æµ‹è¯•æ•°æ®åŠ è½½
print("\n3ï¸âƒ£ æµ‹è¯•æ•°æ®åŠ è½½...")
try:
    data_path = Path(config.config['data']['data_path'])
    file_pattern = config.config['data']['file_pattern']
    data_files = list(data_path.glob(file_pattern))
    
    if not data_files:
        print(f"   âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_path}/{file_pattern}")
        sys.exit(1)
    
    data_file = data_files[0]
    print(f"   âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_file}")
    
    # å¿«é€ŸåŠ è½½æµ‹è¯•ï¼ˆåªåŠ è½½ä¸å¡«å……ï¼‰
    df, _ = load_data(
        file_path=str(data_file),
        time_col='æ—¶é—´',
        p_col='æœ‰åŠŸ',
        q_col='æ— åŠŸ',
        exog_cols=['å®šå­ç”µæµ', 'å®šå­ç”µå‹', 'è½¬å­ç”µå‹', 'è½¬å­ç”µæµ', 'åŠ±ç£ç”µæµ'],
        freq='H',
        imputation_method='nearest_p',
        target_p_value=349
    )
    print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape}")
    
except Exception as e:
    print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 4. æµ‹è¯•ç›®æ ‡åˆ—ç”Ÿæˆ
print("\n4ï¸âƒ£ æµ‹è¯•ç›®æ ‡åˆ—ç”Ÿæˆ...")
try:
    target_cols = []
    if config.get('target', 'predict_p', default=True):
        target_cols.append('P')
    if config.get('target', 'predict_q', default=False):
        target_cols.append('Q')
    
    print(f"   âœ… ç›®æ ‡åˆ—: {target_cols}")
    
except Exception as e:
    print(f"   âŒ ç›®æ ‡åˆ—ç”Ÿæˆå¤±è´¥: {e}")
    sys.exit(1)

# 5. æµ‹è¯•åºåˆ—å‡†å¤‡ï¼ˆå°è§„æ¨¡æµ‹è¯•ï¼‰
print("\n5ï¸âƒ£ æµ‹è¯•åºåˆ—å‡†å¤‡...")
try:
    X, Y = prepare_sequences(
        df=df,
        horizon=1,
        target_cols=target_cols,
        exog_cols=['å®šå­ç”µæµ', 'å®šå­ç”µå‹', 'è½¬å­ç”µå‹', 'è½¬å­ç”µæµ', 'åŠ±ç£ç”µæµ'],
        sequence_length=24
    )
    print(f"   âœ… åºåˆ—å‡†å¤‡æˆåŠŸ: X.shape={X.shape}, Y.shape={Y.shape}")
    
except Exception as e:
    print(f"   âŒ åºåˆ—å‡†å¤‡å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 6. æµ‹è¯•æ—¶é—´åºåˆ—åˆ†å‰²
print("\n6ï¸âƒ£ æµ‹è¯•æ—¶é—´åºåˆ—åˆ†å‰²...")
try:
    splits = list(rolling_origin_split(
        n_samples=len(X),
        test_window=300,
        n_splits=1,
        gap=0
    ))
    train_idx, test_idx = splits[0]
    print(f"   âœ… åˆ†å‰²æˆåŠŸ: è®­ç»ƒé›†={len(train_idx)}, æµ‹è¯•é›†={len(test_idx)}")
    
except Exception as e:
    print(f"   âŒ åˆ†å‰²å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 7. æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒ
print("\n7ï¸âƒ£ æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒ...")
try:
    # ä½¿ç”¨å°æ¨¡å‹å’Œå°æ•°æ®é›†æµ‹è¯•
    X_small = X[:100]
    Y_small = Y[:100]
    
    model = TransformerForecaster(
        d_model=64,
        nhead=8,
        num_encoder_layers=2,
        num_decoder_layers=2,
        dim_feedforward=256,
        dropout=0.1,
        epochs=1,  # åªè®­ç»ƒ1ä¸ªepochç”¨äºæµ‹è¯•
        batch_size=32,
        learning_rate=0.001,
        device='auto',
        n_horizons=1
    )
    print(f"   âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•fit()æ–¹æ³•
    print(f"   ğŸ”„ æµ‹è¯•è®­ç»ƒ (1 epoch, 100 samples)...")
    model.fit(X_small, Y_small)
    print(f"   âœ… è®­ç»ƒæˆåŠŸ")
    
    # æµ‹è¯•predict()æ–¹æ³•
    y_pred = model.predict(X_small[:10])
    print(f"   âœ… é¢„æµ‹æˆåŠŸ: y_pred.shape={y_pred.shape}")
    
except Exception as e:
    print(f"   âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 8. æµ‹è¯•æŒ‡æ ‡è®¡ç®—
print("\n8ï¸âƒ£ æµ‹è¯•æŒ‡æ ‡è®¡ç®—...")
try:
    import numpy as np
    y_true = np.array([100, 200, 300, 400, 500])
    y_pred = np.array([105, 195, 310, 395, 505])
    
    metrics = eval_metrics(
        y_true=y_true,
        y_pred=y_pred,
        metric_names=['RMSE', 'MAE', 'ACC_10']
    )
    print(f"   âœ… æŒ‡æ ‡è®¡ç®—æˆåŠŸ: {metrics}")
    
except Exception as e:
    print(f"   âŒ æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "="*60)
print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡!")
print("="*60)
print("\nğŸ’¡ train_sweep.py åº”è¯¥å¯ä»¥æ­£å¸¸è¿è¡Œ")
print("   å¯ä»¥å®‰å…¨å¯åŠ¨ sweep")
