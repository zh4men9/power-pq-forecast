"""
Main execution script for power quality forecasting project
Runs the complete pipeline: data loading -> training -> evaluation -> reporting
"""
import argparse
from pathlib import Path
import sys
from datetime import datetime
import shutil
import logging

from src.config import load_config
from src.data_io import load_data, generate_diagnostic_plots
from src.train_eval import run_evaluation
from src.plots import plot_error_by_horizon, plot_all_metrics_by_horizon, configure_chinese_fonts

from src.report_docx import generate_word_report
from src.model_manager import save_model, get_best_model_info, make_future_forecast
import pandas as pd


def setup_logging(output_dir: Path):
    """
    è®¾ç½®æ—¥å¿—ç³»ç»Ÿï¼šåŒæ—¶è¾“å‡ºåˆ°æŽ§åˆ¶å°å’Œæ–‡ä»¶
    
    Args:
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = output_dir / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    log_file = log_dir / 'training.log'
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s | %(levelname)s | %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # åˆ›å»ºæ ¹æ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # æŽ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(log_format, date_format)
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter(log_format, date_format)
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)
    
    logging.info(f"æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")
    logging.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    return str(log_file)


def run_single_strategy(config, data_file, output_dir, config_backup_path, imputation_strategy=None):
    """
    è¿è¡Œå•ä¸ªå¡«å……ç­–ç•¥çš„å®Œæ•´æµç¨‹
    
    Args:
        config: é…ç½®å¯¹è±¡
        data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        config_backup_path: å¤‡ä»½çš„é…ç½®æ–‡ä»¶è·¯å¾„
        imputation_strategy: å¡«å……ç­–ç•¥åç§° (Noneè¡¨ç¤ºä½¿ç”¨é…ç½®ä¸­çš„method)
    
    Returns:
        Tuple of (results_df, forecast_df, figures_dir)
    """
    # Load data with specified imputation strategy
    logging.info("="*60)
    logging.info(f"æ­¥éª¤ 2/7: åŠ è½½æ•°æ® (å¡«å……ç­–ç•¥: {imputation_strategy or 'default'})")
    logging.info("="*60)
    
    imputation_config = config.get('data', 'imputation', default={})
    
    # Use specified strategy or fall back to config
    method = imputation_strategy if imputation_strategy else imputation_config.get('method')
    
    df, df_before = load_data(
        file_path=str(data_file),
        time_col=config.get('data', 'time_col'),
        p_col=config.get('data', 'p_col'),
        q_col=config.get('data', 'q_col'),
        exog_cols=config.get('features', 'exog_cols', default=[]),
        freq=config.get('data', 'freq'),
        tz=config.get('data', 'tz'),
        interp_limit=config.get('data', 'interp_limit', default=3),
        imputation_method=method,
        target_p_value=imputation_config.get('target_p_value', 280.0),
        day_copy_days_back=imputation_config.get('day_copy_days_back', 7),
        seasonal_period=imputation_config.get('seasonal_period', 24)
    )
    
    # Generate diagnostic plots with before/after comparison
    strategy_suffix = f"_{imputation_strategy}" if imputation_strategy else ""
    figures_dir = output_dir / f'figures{strategy_suffix}'
    generate_diagnostic_plots(df, df_before=df_before, output_dir=str(figures_dir))
    logging.info("")
    
    # Run evaluation
    logging.info("="*60)
    logging.info("æ­¥éª¤ 3/7: æ¨¡åž‹è®­ç»ƒä¸Žè¯„ä¼°")
    logging.info("="*60)
    
    metrics_dir = output_dir / f'metrics{strategy_suffix}'
    results_df, trained_models = run_evaluation(config, df, metrics_dir=str(metrics_dir))
    logging.info("")
    
    # Save trained models
    logging.info("="*60)
    logging.info("æ­¥éª¤ 4/7: ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡åž‹")
    logging.info("="*60)
    
    models_dir = output_dir / f'models{strategy_suffix}'
    for model_name, model in trained_models.items():
        # Get model performance from results
        model_results = results_df[results_df['model'] == model_name]
        if len(model_results) > 0:
            metadata = {
                'avg_rmse': model_results['RMSE'].mean(),
                'avg_mae': model_results['MAE'].mean(),
                'model_name': model_name
            }
        else:
            metadata = {'model_name': model_name}
        
        save_model(model, model_name, str(models_dir), metadata=metadata)
    
    logging.info(f"âœ“ æ‰€æœ‰æ¨¡åž‹å·²ä¿å­˜è‡³: {models_dir}")
    logging.info("")
    
    # Generate future forecast
    forecast_df = None
    forecast_config = config.get('forecast', default={})
    if forecast_config.get('enabled', False):
        logging.info("="*60)
        logging.info("æ­¥éª¤ 5/7: ç”Ÿæˆæœªæ¥é¢„æµ‹")
        logging.info("="*60)
        
        # Get best model
        target_cols = []
        if config.get('target', 'predict_p', default=True):
            target_cols.append('P')
        if config.get('target', 'predict_q', default=True):
            target_cols.append('Q')
        
        target = target_cols[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªç›®æ ‡å˜é‡
        best_model_info = get_best_model_info(results_df, target=target, metric='RMSE')
        best_model_name = forecast_config.get('best_model', best_model_info['overall_best'])
        
        logging.info(f"æœ€ä¼˜æ¨¡åž‹ï¼ˆåŸºäºŽRMSEï¼‰: {best_model_info['overall_best']}")
        logging.info(f"ä½¿ç”¨æ¨¡åž‹è¿›è¡Œé¢„æµ‹: {best_model_name}")
        
        if best_model_name in trained_models:
            forecast_df = make_future_forecast(
                df=df,
                model=trained_models[best_model_name],
                model_name=best_model_name,
                start_date=forecast_config.get('start_date', '2025-10-20'),
                end_date=forecast_config.get('end_date', '2025-10-22'),
                config=config
            )
            
            # Save forecast results
            if forecast_df is not None and len(forecast_df) > 0:
                forecast_path = output_dir / f'forecast_results{strategy_suffix}.csv'
                forecast_df.to_csv(forecast_path, index=False, encoding='utf-8-sig')
                logging.info(f"âœ“ é¢„æµ‹ç»“æžœå·²ä¿å­˜: {forecast_path}")
        else:
            logging.warning(f"âš ï¸  æ¨¡åž‹ {best_model_name} ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„æµ‹")
        
        logging.info("")
    
    # Generate plots
    logging.info("="*60)
    logging.info("æ­¥éª¤ 6/7: ç”Ÿæˆå›¾è¡¨")
    logging.info("="*60)
    
    configure_chinese_fonts(config.get('plotting', 'font_priority'))
    
    # Plot error by horizon for RMSE
    plot_error_by_horizon(
        results_df,
        metric_name='RMSE',
        output_path=str(figures_dir / 'error_by_horizon_rmse.png'),
        dpi=config.get('plotting', 'fig_dpi', default=150)
    )
    
    # Plot all metrics by horizon
    available_metrics = [m for m in config.get('evaluation', 'metrics', default=[]) 
                        if m in results_df.columns]
    if available_metrics:
        plot_all_metrics_by_horizon(
            results_df,
            metrics=available_metrics,
            output_path=str(figures_dir / 'all_metrics_by_horizon.png'),
            dpi=config.get('plotting', 'fig_dpi', default=150)
        )
    
    logging.info("")
    
    return results_df, forecast_df, figures_dir


def main():
    """Main execution function"""
    # Parse arguments
    parser = argparse.ArgumentParser(description='ç”µåŠ›è´¨é‡é¢„æµ‹é¡¹ç›® - ä¸€é”®è¿è¡Œè„šæœ¬')
    parser.add_argument('--config', type=str, default='config_p_only.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config_exog.yaml)')
    args = parser.parse_args()
    
    # Create timestamped output directory
    timestamp = datetime.now().strftime('%Y-%m-%d-%H%M')
    output_base = Path('outputs')
    output_dir = output_base / f'output-{timestamp}'
    
    # Setup logging (before any other output)
    log_file = setup_logging(output_dir)
    
    # Load configuration
    logging.info("="*60)
    logging.info("æ­¥éª¤ 1/7: åŠ è½½é…ç½®æ–‡ä»¶")
    logging.info("="*60)
    
    config = load_config(args.config)
    logging.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {args.config}")
    logging.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # Copy configuration file to output directory
    config_backup_path = output_dir / 'config_used.yaml'
    output_dir.mkdir(parents=True, exist_ok=True)
    shutil.copy2(args.config, config_backup_path)
    logging.info(f"âœ“ é…ç½®æ–‡ä»¶å·²å¤‡ä»½è‡³: {config_backup_path}")
    logging.info("")
    
    # Find data file
    data_path = config.get('data', 'data_path', default='data/raw')
    file_pattern = config.get('data', 'file_pattern', default='*.xlsx')
    
    data_dir = Path(data_path)
    if not data_dir.exists():
        logging.error(f"é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
        logging.error("è¯·å°†æ•°æ®æ–‡ä»¶æ”¾ç½®åœ¨ data/raw/ ç›®å½•ä¸­")
        sys.exit(1)
    
    data_files = list(data_dir.glob(file_pattern))
    if not data_files:
        logging.error(f"é”™è¯¯: æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®æ–‡ä»¶: {data_path}/{file_pattern}")
        logging.error("è¯·å°†æ•°æ®æ–‡ä»¶æ”¾ç½®åœ¨ data/raw/ ç›®å½•ä¸­")
        sys.exit(1)
    
    data_file = data_files[0]
    logging.info(f"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}")
    logging.info("")
    
    # Check if using multiple imputation strategies
    imputation_config = config.get('data', 'imputation', default={})
    strategies = imputation_config.get('strategies', [])
    
    if strategies and len(strategies) > 0:
        # Multi-strategy mode
        logging.info("="*60)
        logging.info(f"ðŸ”„ å¤šç­–ç•¥æ¨¡å¼: å°†ä¾æ¬¡è¿è¡Œ {len(strategies)} ä¸ªå¡«å……ç­–ç•¥")
        logging.info(f"ç­–ç•¥åˆ—è¡¨: {', '.join(strategies)}")
        logging.info("="*60)
        logging.info("")
        
        report_dir = output_dir / 'report'
        report_dir.mkdir(parents=True, exist_ok=True)
        
        for idx, strategy in enumerate(strategies, 1):
            logging.info("")
            logging.info("â–ˆ"*60)
            logging.info(f"è¿è¡Œç­–ç•¥ [{idx}/{len(strategies)}]: {strategy}")
            logging.info("â–ˆ"*60)
            logging.info("")
            
            try:
                results_df, forecast_df, figures_dir = run_single_strategy(
                    config, data_file, output_dir, config_backup_path, 
                    imputation_strategy=strategy
                )
                
                # Generate Word report for this strategy
                logging.info("="*60)
                logging.info(f"æ­¥éª¤ 7/7: ç”ŸæˆæŠ¥å‘Š (ç­–ç•¥: {strategy})")
                logging.info("="*60)
                
                word_report_path = generate_word_report(
                    results_df,
                    config_path=str(config_backup_path),
                    figures_dir=str(figures_dir),
                    output_path=str(report_dir / f'é¡¹ç›®è¯„ä¼°æŠ¥å‘Š_{strategy}.docx'),
                    forecast_df=forecast_df
                )
                logging.info(f"âœ“ WordæŠ¥å‘Šå·²ç”Ÿæˆ: {word_report_path}")
                logging.info("")
                
            except Exception as e:
                logging.error(f"âŒ ç­–ç•¥ {strategy} è¿è¡Œå¤±è´¥: {e}")
                logging.error(f"è·³è¿‡è¯¥ç­–ç•¥,ç»§ç»­ä¸‹ä¸€ä¸ª...")
                import traceback
                logging.error(traceback.format_exc())
                continue
        
        logging.info("="*60)
        logging.info(f"âœ“ æ‰€æœ‰ç­–ç•¥è¿è¡Œå®Œæˆ! å…±ç”Ÿæˆ {len(strategies)} ä¸ªæŠ¥å‘Š")
        logging.info("="*60)
        
    else:
        # Single strategy mode
        single_method = imputation_config.get('method', 'nearest_p')
        logging.info(f"å•ä¸€ç­–ç•¥æ¨¡å¼: {single_method}")
        logging.info("")
        
        results_df, forecast_df, figures_dir = run_single_strategy(
            config, data_file, output_dir, config_backup_path, 
            imputation_strategy=None
        )
        
        # Generate report
        logging.info("="*60)
        logging.info("æ­¥éª¤ 7/7: ç”ŸæˆæŠ¥å‘Š")
        logging.info("="*60)
        
        report_dir = output_dir / 'report'
        
        word_report_path = generate_word_report(
            results_df,
            config_path=str(config_backup_path),
            figures_dir=str(figures_dir),
            output_path=str(report_dir / 'é¡¹ç›®è¯„ä¼°æŠ¥å‘Š.docx'),
            forecast_df=forecast_df
        )
        logging.info(f"WordæŠ¥å‘Šå·²ç”Ÿæˆ: {word_report_path}")
    
    # Copy to latest outputs folder for convenience
    latest_dir = output_base / 'latest'
    if latest_dir.exists():
        shutil.rmtree(latest_dir)
    shutil.copytree(output_dir, latest_dir)
    
    # Summary
    logging.info("="*60)
    logging.info("è¿è¡Œå®Œæˆ!")
    logging.info("="*60)
    logging.info(f"æœ¬æ¬¡è¿è¡Œè¾“å‡ºç›®å½•: {output_dir}")
    logging.info(f"æœ€æ–°ç»“æžœé“¾æŽ¥: {latest_dir}")
    logging.info(f"  - æ—¥å¿—æ–‡ä»¶: {log_file}")
    if strategies and len(strategies) > 0:
        logging.info(f"  - æŠ¥å‘Šç›®å½•: {report_dir} (å…± {len(strategies)} ä¸ªæŠ¥å‘Š)")
    else:
        logging.info(f"  - æŠ¥å‘Šç›®å½•: {report_dir}")
    logging.info("="*60)


if __name__ == '__main__':
    main()
