# 电力有功预测项目配置文件 - 仅预测有功功率
# Power Forecasting Configuration - Active Power Only

# 设备配置
device:
  type: "auto"  # 自动检测最快的设备 (优先级: cuda > mps > cpu)
  # auto: 自动检测 (优先级: cuda > mps > cpu)
  # cpu: 强制使用CPU (小模型推荐，稳定快速)
  # mps: 强制使用Apple Metal (需要大batch size才有优势)
  # cuda: 强制使用NVIDIA GPU

# 数据配置
data:
  data_path: "data/raw"
  file_pattern: "*.csv"
  time_col: "时间"
  p_col: "有功"
  q_col: "无功"  # 仍然加载，但仅用于缺失值填补
  freq: "H"
  tz: null
  interp_limit: 3
  # 缺失值填补配置
  imputation:
    # 多策略循环模式: 依次运行每个策略,每个策略生成独立的报告
    # 如果配置了strategies列表,将忽略method字段
    strategies:
      - nearest_p
      - day_copy
      - seasonal
      - mean
      - median
      - interpolate
      - forward
      - backward
    
    # 单一方法模式 (如果strategies未配置或为空,则使用此方法)
    # method: "nearest_p"  # 可选: nearest_p, forward, backward, interpolate, mean, median, day_copy, seasonal
    
    # 各方法的参数
    target_p_value: 400     # nearest_p方法的目标有功功率值
    day_copy_days_back: 7   # day_copy方法: 回溯天数
    seasonal_period: 24     # seasonal方法: 季节周期(小时数据用24表示日周期)

# 预测目标配置
target:
  predict_p: true   # 预测有功功率
  predict_q: false  # 不预测无功功率

# 特征工程配置
features:
  max_lag: 72  # 增加到72以捕获更长的历史模式
  roll_windows:
    - 6
    - 12
    - 24
    - 48   # 新增: 2天的滚动窗口
    - 168  # 新增: 1周的滚动窗口
  use_time_features: true
  sequence_length: 72  # 增加到72(3天)以捕获更多历史信息
  season_length: 24
  exog_cols:  # 使用电气特征作为外生变量
    - '定子电流'
    - '定子电压'
    - '转子电压'
    - '转子电流'
    - '励磁电流'

# 评估配置
evaluation:
  horizons: "1,2,3,4,5,6,7,8,9,10,11,12"  # 预测步长 (支持逗号分隔字符串或列表)
  test_window: 600  # 增加到600小时(25天)以获得更稳定的评估结果
  n_splits: 1  # 使用3折交叉验证提高结果可靠性
  metrics:
    - RMSE
    - MAE
    - SMAPE
    - WAPE
    - ACC_5   # 5%阈值准确率
    - ACC_10  # 10%阈值准确率
  deep_learning_strategy: "multiple_output"  # 可选: "direct" 或 "multiple_output"

# 模型配置
models:
  # 朴素基线
  naive:
    enabled: true
  
  # 季节朴素基线
  seasonal_naive:
    enabled: true
  
  # 随机森林
  rf:
    enabled: true
    n_estimators: 100
    max_depth: null
    n_jobs: -1
  
  # XGBoost
  xgb:
    enabled: true
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    n_jobs: -1
  
  # LSTM
  lstm:
    enabled: true
    hidden_size: 128  # 增加模型容量
    num_layers: 2
    dropout: 0.2  # 降低dropout以减少欠拟合
    epochs: 100
    batch_size: 64
    learning_rate: 0.001
  
  # Transformer
  transformer:
    enabled: true
    d_model: 128  # 增加模型容量 (从64->128)
    nhead: 8  # 增加注意力头数量 (从4->8)
    num_encoder_layers: 3  # 增加编码器层数 (从2->3)
    num_decoder_layers: 3  # 增加解码器层数 (从2->3)
    dim_feedforward: 512  # 增加前馈网络维度 (从256->512)
    dropout: 0.1  # 降低dropout (从0.2->0.1)
    epochs: 200
    batch_size: 64  # 增加批次大小 (从32->64)
    learning_rate: 0.0005

# 预测配置
forecast:
  enabled: true
  start_date: "2025-10-20"
  end_date: "2025-10-22"
  best_model: "Transformer"  # 使用效果最好的模型

# 图形配置
plotting:
  fig_dpi: 150
  font_priority:
    - SimHei
    - Microsoft YaHei
    - STHeiti
    - PingFang SC
    - Heiti SC
    - WenQuanYi Micro Hei
    - Noto Sans CJK SC
    - DejaVu Sans
    - Arial Unicode MS

# 报告配置
report:
  generate_word: true      # 生成Word报告
  generate_markdown: true  # 生成Markdown报告
  include_forecast_table: true  # 包含预测结果表格
